---
title: "Final_Project: Customer Lifetime Value"
author: "Team Binalytics: Maggie Lu (yaol4) and Wenyan Zhao (wenyanz)"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#load library
library(dplyr)
library(knitr)
library(plyr)
library(ggplot2)
library(leaps)
library(glmnet)
library(caret)
library(pROC)
library(tidyverse)
library(klaR)
library(rpart)
library(randomForest)
library(lubridate)
library(factoextra)
library(ape)
library(gplots)
library(RColorBrewer)
#Load data
ltv = read.csv(file = 'ltv.csv', header = TRUE)
#suppress warnings
```

### Task 1: Attrition Model
> To build an attrition model, first we want to clean up the data a bit to aggregate the information of each customer within a specifically defined timeframe. Here we would like to define the time interval to be 1 month-- partially because it is easier to aggregate, and therefore we define the near future to be the next month, in accordance with our dataframe. We then split the data into a test set and a training set, and then determines which of the variables we want to look into using subset selection criterias-- AIC/BIC. Finally, we look into different classfication models-- logistic regression, Naive Bayes and random forest to see which one has the best accuracy and specificity

#### Pre-processing the Data
```{r message=FALSE, warning=FALSE}

#Create a new data frame capturing the end state and the time the customer's in the system
#First of all transform the data: 

df <- ltv %>%
  group_by(id) %>%
dplyr::  mutate(duration = ifelse(as.Date(date)==min(as.Date(date)),1,ceiling(((as.Date(date)-min(as.Date(date))))/30)))

df = ddply(df,c("id","gender","duration"),summarize, cancelled = max(status), days.count = length(date), page.visited=sum(pages),time.spent=sum(onsite),entered.time = sum(entered), cmplt.time = sum(completed),holiday = max(holiday))

df.new = ddply(df,.(id),transform,csum.days= cumsum(days.count),csum.page=cumsum(page.visited),csum.onsite= cumsum(time.spent), csum.entered = cumsum(entered.time), csum.cmplt.time = cumsum(cmplt.time))

df.new$cancelled = mapvalues(df.new$cancelled, from=c('0','1','2'),to=c(0,0,1))

ltv.cleaned = df.new[,c(2,3,4,10,11,12,13,14,15)]
```

#### Processing and Methods
```{r message=FALSE, warning=FALSE}
#First split the dataset into a training set and a test set
data(ltv.cleaned)
## 70% of the sample size
smp_size <- floor(0.7 * nrow(ltv.cleaned))
## set the seed to make your partition reproductible
set.seed(123)
train_ind <- sample(seq_len(nrow(ltv.cleaned)), size = smp_size)
ltv.train <- ltv.cleaned[train_ind, ]
ltv.test <- ltv.cleaned[-train_ind, ]

#Best subset
df.subset <- regsubsets(cancelled ~ .,
               data = ltv.train,
               nbest = 1,    # 1 best model for each number of predictors
               nvmax = NULL,    # NULL for no limit on number of variables
               method = "exhaustive", really.big = TRUE)
df.subset.sum = summary(df.subset)
df.subset.sum

#AIC
which.min(df.subset.sum$cp)
names(coef(df.subset,which.min(df.subset.sum$cp)))
 
#BIC
which.min(df.subset.sum$bic)
names(coef(df.subset,which.min(df.subset.sum$bic)))
```
> This makes sense. We will then use several models to determine the fit.

#### Validation and Metrics
```{r message=FALSE, warning=FALSE}
#Method 1: Logistic Regressions
glm.fit = glm(cancelled ~ .,family = binomial(), data = ltv.train)
#fit the prediction to the test data, and transform the test data with a cut off of 0.5 to see the confusion matrix for fitting
test.pred.prec = predict(glm.fit,ltv.test,type='response')
test.pred = ifelse(test.pred.prec < 0.4,0,1)
confusionMatrix(data = test.pred, reference = ltv.test$cancelled)
#ROC plot
roc.obj = roc(ltv.test$cancelled, test.pred.prec)
plot.roc(roc.obj, legacy.axes=TRUE)
```
> The accuracy and sensitivity are both quite high in this scenario. In this case, we care more about the sensitivity than the specificity. We also explored the performance of Naive Bayes and Random Forest. 

```{r message=FALSE, warning=FALSE}
#Method 2: Naive Bayes
#suppress warnings
options(warn=-1)
ltv.train$cancelled <- factor(ltv.train$cancelled)
ltv.train.nb <- NaiveBayes(cancelled ~., data = ltv.train, usekernel = TRUE)
confusionMatrix(predict(ltv.train.nb, ltv.test, type="class")$class, ltv.test$cancelled)

#density plot
```
> From the density plot it is evident that there are a lot of overlapping between 


```{r message=FALSE, warning=FALSE}
#Method 3: Random Forest
ltv.rf = randomForest(cancelled ~ .,data=ltv.train, importance=TRUE)
print(ltv.rf)

pred = predict(ltv.rf, ltv.test)
confusionMatrix(pred, ltv.test$cancelled)
```

### Task 2: Lifetime Value of A customer
```{r}
#first, find about customer behavior for a year for every customer
#then the y value would be the one that extend beyond the one year mark until the churn time. 
#this is user-level behavior that we are trying to predict, therefore group the data by user_id
df2.test  = ddply(ltv,c("id"),mutate,yr_status = ifelse(as.Date(date)<=min(as.Date(date))+365,"<1yr",">1yr"),total.days.spent = max(as.Date(date))-min(as.Date(date)))
df2.test = ddply(df2.test,c("id","gender","yr_status","total.days.spent"),summarize, cancelled = max(status), days.count = length(date),days.left=max(as.Date(date))- min(as.Date(date)),page.visited=sum(pages),time.spent=sum(onsite),entered.time = sum(entered), cmplt.time = sum(completed),holiday = sum(holiday), min_date = min(as.Date(date)),max_date = max(as.Date(date)))

df2 = ddply(ltv,c("id","gender"),summarize, cancelled = max(status), days.count = max(as.Date(date))-min(as.Date(date)))
#filter out the customers who have bene using this service for at least a year-- these are the customers we want to measure value for
df2= df2[df2$days.count>365,]
df2.filtered = df2.test %>%
      filter(id %in% df2$id)

df2.filtered$cancelled = mapvalues(df2.filtered$cancelled, from=c('0','1','2'),to=c(0,0,1))
df2.behavior = df2.filtered[df2.filtered$yr_status=="<1yr",]
df2.prediction = df2.filtered[df2.filtered$yr_status==">1yr",]
df2.prediction$year.end= df2.prediction$max_date-df2.prediction$total.days.spent+365
df2.prediction$lifetime= ifelse(df2.prediction$cancelled==1,df2.prediction$max_date-df2.prediction$year.end,as.Date("2014-12-31")-df2.prediction$year.end)
df2.prediction = df2.prediction[,c(1,2,16)]
df2.final = merge(df2.behavior,df2.prediction,by="id")[,c(2,6,8,9,10,11,12,16)]
```

```{r}
#Examination of the correlation between the variables
ltv.var.names = c("gender.x","days.count", "page.visited", "time.spent", "entered.time","cmplt.time","holiday")
panel.cor <- function(x, y, digits = 2, prefix = "", cex.cor, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y))
    txt <- format(c(r, 0.123456789), digits = digits)[1]
    txt <- paste0(prefix, txt)
    if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)
    text(0.5, 0.5, txt, cex = pmax(1, cex.cor * r))
}

# Use panel.cor to display correlations in lower panel.
pairs(df2.final[,ltv.var.names], lower.panel = panel.cor)
```
```{r message=FALSE, warning=FALSE}
#First split the dataset into a training set and a test set
data(df2.final)
## 70% of the sample size
smp_size <- floor(0.7 * nrow(df2.final))
## set the seed to make your partition reproductible
set.seed(123)
train_ind <- sample(seq_len(nrow(df2.final)), size = smp_size)
ltv.train <- df2.final[train_ind, ]
ltv.test <- df2.final[-train_ind, ]

#Best subset
df.subset <- regsubsets(lifetime ~ .,
               data = df2.final,
               nbest = 1,    # 1 best model for each number of predictors
               nvmax = NULL,    # NULL for no limit on number of variables
               method = "exhaustive", really.big = TRUE)
df.subset.sum = summary(df.subset)
df.subset.sum

#AIC
which.min(df.subset.sum$cp)
names(coef(df.subset,which.min(df.subset.sum$cp)))
 
#BIC
which.min(df.subset.sum$bic)
names(coef(df.subset,which.min(df.subset.sum$bic)))

#Forward Stepwise Selection
options(max.print=999999)
ltv.forward.subset <- regsubsets(lifetime ~ .,
               data = df2.final,
               nbest = 1,    # 1 best model for each number of predictors
               nvmax = NULL,    # NULL for no limit on number of variables
               method = "forward")

summary(ltv.forward.subset)
```


```{r}




```
### Task 3: Customer Segmentation Scheme
#### Processing and Methods
```{r}
# create a data frame with new variables `duration` and `recency`.`duration` measures how many months a customer matains status==1 in the system, and `recency` meausres how many days since a user last logged in. 

df3 <- ltv 
df3$date <- ymd(df3$date)

df3 <- df3 %>%
  group_by(id) %>% 
  dplyr::mutate(duration = ifelse(date == min(date), 1, ifelse(status==2, ceiling((((date) - min(date))/30)), ceiling((as.Date("2014-12-31") - min(date))/30))), recency = round((as.Date("2014-12-31")-max(date))/30, digits = 1)) 
  
# Filter down to customer whose status =1
rmf <- df3 %>% 
  filter(row_number()==n()) %>% 
  filter(status==1) %>% 
  dplyr::select(id,duration,recency) 


```
#### Validation and Metrics
```{r}
#Method 1: K-means

# Standardize variables to have mean zero and standard deviation one.
rmf$duration=as.numeric(rmf$duration)
rmf$recency=as.numeric(rmf$recency)
rmf<- as_tibble(rmf)
rmf.scale <- rmf[-1] %>% as.matrix %>% scale

set.seed(1234)
km.out =kmeans (rmf.scale,3, nstart =20)
km.out$centers
plot(rmf.scale, col=(km.out$cluster+1), main="K-Means Clustering Results with K=3", xlab="Duration", ylab="Recency", pch=20, cex=2)

rmf.scale %>%
  as_tibble() %>%
  mutate(cluster = km.out$cluster, id = rmf$id) %>%
  ggplot(aes(duration, recency, color = factor(cluster), label = id)) +
  geom_text()

# Unscale k-means' centers
scale.scale = as.data.frame(attr(rmf.scale,'scaled:scale'))
scale.center = as.data.frame(attr(rmf.scale,'scaled:center'))
center.unscale = as.data.frame(km.out$centers)
center.unscale$unsl.duration = (center.unscale$duration)*scale.scale[1, ] + scale.center[1, ]
center.unscale$unsl.recency = (center.unscale$recency)*scale.scale[2, ] + scale.center[2, ]
center.unscale

set.seed(1234)

# Determine optimal clusters

fviz_nbclust(rmf.scale, kmeans, method = "wss")
fviz_nbclust(rmf.scale, kmeans, method = "silhouette")

```

```{r}
#Method 2: Hierarchical clustering
hc.complete <- hclust(dist(rmf.scale), method="complete")
hc.average <- hclust(dist(rmf.scale), method="average")
hc.single <- hclust(dist(rmf.scale), method="single")

# fviz_nbclust(rmf.scale, FUN = hcut, method = "wss")
# fviz_nbclust(rmf.scale, FUN = hcut, method = "silhouette")

par(mfrow = c(1,3))
plot(rmf.scale, col=(cutree(hc.complete, 3)+1), main="Complete linkage clustering with K=2", xlab="", ylab="", pch=20, cex=2)
plot(rmf.scale, col=(cutree(hc.average, 3)+1), main="Average linkage clustering with K=2", xlab="", ylab="", pch=20, cex=2)
plot(rmf.scale, col=(cutree(hc.single, 3)+1), main="Single linkage clustering with K=2", xlab="", ylab="", pch=20, cex=2)

sub_grp <- cutree(hc.single, k = 4)
table(sub_grp)

# Set colours for heatmap, 25 increments
my_palette <- colorRampPalette(brewer.pal(9, "GnBu"))(100)

# Plot heatmap with heatmap.2
par(cex.main=0.75) # Shrink title fonts on plot
gplots::heatmap.2(rmf.scale,                     # Tidy, normalised data
          dendrogram = "row",
          Colv="NA",     # Experiments clusters in cols
          Rowv=dend,     # Protein clusters in rows
          trace="none",               # Turn of trace lines from heat map
          margins =c(5,0.1), 
          density.info = "density",
          col = my_palette,           # Use my colour scheme
          cexRow=0.5,cexCol=0.75)     # Amend row and column label fonts

```

### Summary of Findings
